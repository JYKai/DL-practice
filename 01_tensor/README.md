# Tensor
딥러닝 프로세스는 입력을 부동소수점 수로 변환하는 것부터 시작한다.

## | 부동소수점 수의 세계 |
데이터 처리와 저장을 위해 파이토치에서는 **텐서(Tensor)**라는 기본 자료구조를 제공한다.
- 딥러닝에서의 텐서는 임의의 차원을 가진 벡터나 행렬의 일반화된 개념으로 생각하면 된다. 따라서, 다차원 배열이라고도 부른다.

</br>

## | 텐서: 다차원 배열 |
텐서는 한 개나 여러 개의 인덱스를 사용해 개별적으로 값에 접근할 수 있는 형태의 숫자 모음을 저장하는 자료구조이다.

```python
import torch

a = torch.ones(3) # 크기가 3인 1차원 텐서를 만들고 값을 1로 채우기

>>> tensor([1., 1., 1.])
```

### 텐서의 핵심
**파이썬의 리스트나 튜플 객체**
- 메모리에 따로따로 할당

**파이토치 텐서나 넘파이 배열**
- 파이썬 객체가 아닌 언박싱된 C 언어의 숫자 타입을 포함한 연속적인 메모리가 할당되고 이에 대한 뷰를 제공
- 각 요소는 32비트 float타입

```python
# 2차원 텐서

points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])
>>> tensor([[4., 1.],
            [5., 3.],
            [2., 1.]])

points.shape
>>> torch.Size([3, 2])
```

</br>

## | 텐서 인덱싱 |
```python
points[1:]      # 첫 번째 이후 모든 행에 대해, 암묵적으로 모든 열이 포함
points[1:, :]   # 첫 번째 이후 모든 행에 대해, 명시적으로 모든 열이 포함
points[1:, 0]   # 첫 번째 이후 모든 행에 대해, 첫 번째 열만 포함
prints[None]    # 길이가 1인 차원을 추가함 = unsqueeze
```

</br>

## | 텐서 요소 타입 |
### dtype으로 숫자 타입 지정하기
tensor나 zeros, ones 같은 텐서 생성자 실행 시 넘겨주는 dtype 인자로 텐서 내부에 들어갈 데이터 타입을 지정할 수 있다.
- torch.float32 or torch.float : 32비트 단정밀도 부동소수점
- torch.float64 or torch.double : 64비트 배정밀도 부동소수점
- torch.float16 or torch.half : 16비트 반정밀도 부동소수점
- torch.int8 : 부호 있는 8비트 정수
- torch.uint8 : 부호 없는 8비트 정수
- torch.int16 or torch.short : 부호 있는 16비트 정수
- torch.int32 or torch.int : 부호 있는 32비트 정수
- torch.int64 or torch.long : 부호 있는 64비트 정수
- torch.bool : 불리언 

### 텐서의 dtype 속성 관리
기본 데이터 타입은 32비트 부동소수점이다.</br>
신경망 연산은 대부분 32비트 부동소수점 연산이다.</br>
여러 타입을 가진 입력들이 연산을 거치며 서로 섞일 때 자동으로 제일 큰 타입으로 만들어진다.
  
</br>

## | 텐서를 저장소 관점에서 머릿속에 그려보기 |
텐서 내부 값은 실제로는 torch.Storage 인스턴스로 관리하며, 연속적인 메모리 조각으로 할당된 상태이다. 저장 공간은 숫자 데이터를 가진 1차원 배열이다.
  
Tensor 객체는 이러한 저장 공간을 나타내는 Storage 객체에 대한 뷰 역할을 담당하고, 오프셋을 사용해서 공간의 임의 위치에 접근하거나 특정 차원의 크기를 단위로 해서 접근할 수 있다.

```python
points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])
points.storage()

>>>
4.0
1.0
5.0
3.0
2.0
1.0
[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]
```
- points 텐서는 세 개의 행과 두 개의 열로 이루어져 있지만 실제로는 크기가 6인 배열 공간일 뿐이다.
- 저장공간으로 접근하여 값을 바꾸면 참조하고 있는 텐서에서의 내용도 바뀌게 된다.

**저장된 값 수정: 텐서 내부 연산**
- 밑줄(_)로 끝나는 연산의 결과는 새 텐서가 넘어오는 대신 기존 텐서의 내용이 바뀐다.

</br>

## | 텐서 메타데이터: 사이즈, 오프셋, 스트라이드 |

**사이즈** </br>
텐서의 사이즈는 텐서의 각 차원 별로 들어가는 요소의 수를 표시한 튜플이다,

**오프셋** </br>
텐서의 첫 번째 요소를 가리키는 색인 값

**스트라이드** </br>
각 차원에서 다음 요소를 가리키고 싶을 때 실제 저장 공간상에서 몇 개의 요소를 건너뛰어야 하는지를 알려주는 숫자

</br>

## | 인접한 텐서 |
파이토치 텐서 연산 중에는 인접한 텐서에 대해서만 동작하는 경우가 있다.  
```contiguous()``` 메소드를 사용하면 인접하지 않은 텐서를 인접한 텐서로 만들 수 있다.
- 값은 동일하나, 값의 배치와 스트라이드가 바뀐 텐서가 만들어진다.

</br>

## | 텐서를 GPU로 옮기기 |
생성자에 ```device()``` 인자를 지정하여 텐서를 GPU에 만든다.  
```to(device='cuda)``` 를 통해 CPU에 만들어진 텐서를 GPU로 옮길 수 있다.
    - device와 dtype 인자를 동시에 사용해서 데이터 타입과 데이터 위치를 동시에 변경할 수 있다.

</br>

## | 넘파이 호환 |
파이토치 텐서와 넘파이 배열의 변환은 매우 효율적으로 이뤄진다.  
```numpy()``` 메소드를 통해 텐서를 넘파이 배열로 변경할 수 있다.
```python
points_np = points.numpy()
```
- 텐서가 GPU에 할당되어 있다면 파이토치는 넘파이 배열로의 변환 과정에서 CPU 영역으로 텐서 내용을 복사해서 배열을 만든다.  
```python
points = torch.from_numpy(points_np)
```
- 넘파이 배열을 텐서로 변환한다.

</br>

## | 텐서 직렬화 |
파이토치는 텐서 객체를 직렬화하기 위해 내부적으로 pickle을 사용하며, 저장 공간을 위한 전용 직렬화 코드를 가지고 있다.

### h5py로 HDF5 병렬화하기
다른 라이브러리에 의존하는 시스템이 있는 상태에서 파이토치를 도입하는 경우라면 텐서를 호환 가능한 형태로 저장해야 한다.

**HDF5**
- 이식성이 높고, 광범위하게 지원되는, 중첩된 키-값 딕셔너리에서 직렬화된 정형 다차원 배열을 표현하는 포맷
- 파이썬은 h5py 라이브러리를 통해 HDF5 포맷을 지원한다.
- 데이터가 디스크에 있는 상태에서 원하는 요소만 인덱스로 직접 접근하도록 지원해준다.